

import re




def convert_non_ascii(txt):
    # we see tokens like:
    #   'Ã©tat', 'Ãªtre',
    # 'Ãºltimahora', 'Î¼Î¿Î»Ï‰Î½Î»Î±Î²Îµ', 'Ù‚Ø§Ø³Ù…_Ø³Ù„ÙŠÙ…Ø§Ù†ÙŠ', 'ğ”ğğ‡ğˆğğ†ğ„ğƒ', 'ğœğ¨ğ®ğ§ğ­ğ«ğ²',
    # 'ğğšğ²ğ¬', 'ğ¨ğ®ğ«', 'ğ©ğ¨ğ¥ğ¢ğ­ğ¢ğœğ¬', 'ğ®ğ¬', 'ğ‘¤ğ‘’ğ‘ğ‘˜ğ‘’ğ‘ ğ‘¡', 'ğ‘±ğ‘¶ğ‘¯ğ‘µ', 'ğ‘¹ğ‘¶ğ‘©ğ‘¬ğ‘¹ğ‘»ğ‘º',
    # 'ğ”½ğ•†â„ğ”¼ğ•ğ”¼â„', 'ğ•‹ğ•™ğ•’ğ•¥', 'ğ•–ğ•ğ•“ğ•’ğ•£ğ•£ğ•’ğ•¤ğ•¤ğ•šğ•Ÿğ•˜', 'ğ•›ğ•¦ğ•¤ğ•¥', 'ğ—–ğ—¿ğ—¼ğ—½ğ˜€', 'ğ——ğ—¡ğ—–', 'ğ——ğ—®ğ—¶ğ—¹ğ˜†',
    # 'ğ—˜ğ—¡ğ——ğ—¢ğ—¥ğ—¦ğ—˜ğ——', 'ğ—˜ğ—¡ğ—™ğ—¢ğ—¥ğ—–ğ—˜ğ—¦', 'ğ—ğ—¢ğ—¬', 'ğ—ğ—¢ğ—¬ğ—¦', 'ğ—Ÿğ—²ğ—®ğ—±ğ—¶ğ—»ğ—´', 'ğ—¡ğ—¢', 'ğ—¢ğ—™',
    # 'ğ—£ğ—¹ğ—®ğ˜†ğ—¯ğ—¼ğ—¼ğ—¸', 'ğ—¥ğ—²ğ—ºğ—¶ğ—»ğ—±ğ—²ğ—¿', 'ğ—¦ğ˜ğ—®ğ˜ğ—²ğ˜€', 'ğ—©ğ—²ğ—´ğ—²ğ˜ğ—®ğ—¯ğ—¹ğ—²ğ˜€', 'ğ—°ğ—¿ğ—²ğ—±ğ—¶ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜†',
    # 'ğ—³ğ—¼ğ—¿ğ—²ğ˜ƒğ—²ğ—¿', 'ğ—¶ğ—ºğ—½ğ—²ğ—®ğ—°ğ—µğ—²ğ—±', 'ğ—¶ğ—»', 'ğ—¶ğ—»ğ—²ğ˜ƒğ—¶ğ˜ğ—®ğ—¯ğ—¹ğ—²', 'ğ—»ğ—²ğ˜ƒğ—²ğ—¿', 'ğ—»ğ—¼',
    # 'ğ™€ğ™¢ğ™—ğ™¤ğ™¡ğ™™ğ™šğ™£', 'ğ™›ğ™–ğ™¢ğ™ğ™¡ğ™®', 'ğ™›ğ™šğ™šğ™¡', 'ğ™œğ™§ğ™¤ğ™ªğ™¥', 'ğ™ğ™ğ™¨', 'ğ™ğ™£', 'ğ™ ğ™ğ™™ğ™¨', 'ğ™¨ğ™–ğ™™'

    # so we'll convert to keep their meaning:

    terms_map = {
        'Ã©tat': 'etat',
        'Ãªtre': 'etre',
        'Ãºltimahora': 'ultimahora',
        'Î¼Î¿Î»Ï‰Î½Î»Î±Î²Îµ': 'molonlabe',
        'Ù‚Ø§Ø³Ù…_Ø³Ù„ÙŠÙ…Ø§Ù†ÙŠ': 'Qasem_Soleimani',
        'ğ”ğğ‡ğˆğğ†ğ„ğƒ': 'UNHINGED',
        'ğœğ¨ğ®ğ§ğ­ğ«ğ²': 'country',
        'ğğšğ²ğ¬': 'days',
        'ğ¨ğ®ğ«': 'our',
        'ğ©ğ¨ğ¥ğ¢ğ­ğ¢ğœğ¬': 'politics',
        'ğ®ğ¬': 'us',
        'ğ‘¤ğ‘’ğ‘ğ‘˜ğ‘’ğ‘ ğ‘¡': 'weakest',
        'ğ‘±ğ‘¶ğ‘¯ğ‘µ': 'JOHN',
        'ğ‘¹ğ‘¶ğ‘©ğ‘¬ğ‘¹ğ‘»ğ‘º': 'ROBERTS',
        'ğ”½ğ•†â„ğ”¼ğ•ğ”¼â„': 'FOREVER',
        'ğ•‹ğ•™ğ•’ğ•¥': 'That',
        'ğ•–ğ•ğ•“ğ•’ğ•£ğ•£ğ•’ğ•¤ğ•¤ğ•šğ•Ÿğ•˜': 'embarrassing',
        'ğ•›ğ•¦ğ•¤ğ•¥': 'just',
        'ğ—–ğ—¿ğ—¼ğ—½ğ˜€': 'Crops',
        'ğ——ğ—¡ğ—–': 'DNC',
        'ğ——ğ—®ğ—¶ğ—¹ğ˜†': 'Daily',
        'ğ—˜ğ—¡ğ——ğ—¢ğ—¥ğ—¦ğ—˜ğ——': 'ENDORSED',
        'ğ—˜ğ—¡ğ—™ğ—¢ğ—¥ğ—–ğ—˜ğ—¦': 'ENFORCES',
        'ğ—ğ—¢ğ—¬': 'JOY',
        'ğ—ğ—¢ğ—¬ğ—¦': 'JOYS',
        'ğ—Ÿğ—²ğ—®ğ—±ğ—¶ğ—»ğ—´': 'Leading',
        'ğ—¡ğ—¢': 'NO',
        'ğ—¢ğ—™': 'OF',
        'ğ—£ğ—¹ğ—®ğ˜†ğ—¯ğ—¼ğ—¼ğ—¸': 'Playbook',
        'ğ—¥ğ—²ğ—ºğ—¶ğ—»ğ—±ğ—²ğ—¿': 'Reminder',
        'ğ—¦ğ˜ğ—®ğ˜ğ—²ğ˜€': 'States',
        'ğ—©ğ—²ğ—´ğ—²ğ˜ğ—®ğ—¯ğ—¹ğ—²ğ˜€': 'Vegetables',
        'ğ—°ğ—¿ğ—²ğ—±ğ—¶ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜†': 'credibility',
        'ğ—³ğ—¼ğ—¿ğ—²ğ˜ƒğ—²ğ—¿': 'forever',
        'ğ—¶ğ—ºğ—½ğ—²ğ—®ğ—°ğ—µğ—²ğ—±': 'impeached',
        'ğ—¶ğ—»': 'in',
        'ğ—¶ğ—»ğ—²ğ˜ƒğ—¶ğ˜ğ—®ğ—¯ğ—¹ğ—²': 'inevitable',
        'ğ—»ğ—²ğ˜ƒğ—²ğ—¿': 'never',
        'ğ™€ğ™¢ğ™—ğ™¤ğ™¡ğ™™ğ™šğ™£': 'Embolden',
        'ğ™›ğ™–ğ™¢ğ™ğ™¡ğ™®': 'family',
        'ğ™›ğ™šğ™šğ™¡': 'feel',
        'ğ™œğ™§ğ™¤ğ™ªğ™¥': 'group',
        'ğ™ğ™ğ™¨': 'his',
        'ğ™ğ™£': 'in',
        'ğ™ ğ™ğ™™ğ™¨': 'kids',
        'ğ™¨ğ™–ğ™™': 'sad',
        'ğ—»ğ—¼': 'no',
        'ğ™©ğ™šğ™­ğ™©': 'text',

        # these don't work ?:
        'zÃ¼rich': 'zurich',
        'Ãºltimahora': 'ultimahora',
        'Î¼Î¿Î»Ï‰Î½Î»Î±Î²Îµ': 'molonlabe', # come and take them

    }

    for k, v in terms_map.items():
        txt = txt.replace(k, v)

    # despite best efforts, remove any remaining non-asci:

    non_ascii_pattern = re.compile(r'[^\x00-\x7F]+')
    txt = non_ascii_pattern.sub('', txt)

    return txt
