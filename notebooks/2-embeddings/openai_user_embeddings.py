# -*- coding: utf-8 -*-
"""User Profile Embeddings (OpenAI API)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ddF7ZqEL6rMPKy2OmSn1dd6IltPZjSSx

## Setup

### Google Drive
"""

import os
from google.colab import drive

drive.mount('/content/drive')
print(os.getcwd(), os.listdir(os.getcwd())) #> 'content', ['.config', 'drive', 'sample_data']

# you might need to create a google drive SHORTCUT that has this same path
# ... or update the path to use your own google drive organization
DATA_DIR = '/content/drive/MyDrive/Research/DS Research Shared 2023/data/impeachment_2020'
print(DATA_DIR)
assert os.path.isdir(DATA_DIR)

users_sample_csv_filepath = os.path.join(DATA_DIR, "users_sample_by_account_type_v2_and_their_tweets.csv")
assert os.path.isfile(users_sample_csv_filepath)

"""### OpenAI API Service"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# 
# !pip install openai

from getpass import getpass

OPENAI_API_KEY = getpass("Please provide your OpenAI API Key: ")
print("...", OPENAI_API_KEY[-4:])

"""
  + https://github.com/openai/openai-python
  + https://platform.openai.com/account/api-keys
  + https://platform.openai.com/docs/introduction/key-concepts
  + https://platform.openai.com/docs/models/overview
  + https://platform.openai.com/docs/guides/embeddings/what-are-embeddings
  + https://platform.openai.com/docs/guides/embeddings/embedding-models

> We recommend using `text-embedding-ada-002` for nearly all 
 (Embedding) use cases. It's better, cheaper, and simpler to use. Read the blog post announcement.
"""

import openai
from openai import Model, Embedding
from pandas import DataFrame

openai.api_key = OPENAI_API_KEY

MODEL_ID = "text-embedding-ada-002"

class OpenAIService():
    def __init__(self, model_id=MODEL_ID):
        self.model_id = model_id

    def get_models(self):
        models = Model.list()
        #print(type(models)) #> openai.openai_object.OpenAIObject

        records = []
        for model in sorted(models.data, key=lambda m: m.id):
            #print(model.id, "...", model.owned_by, "...", model.parent, "...", model.object)
            model_info = model.to_dict()
            del model_info["permission"] # nested list
            #print(model_info)
            records.append(model_info)

        models_df = DataFrame(records)
        #models_df.to_csv("openai_models.csv")
        #models_df.sort_values(by=["id"])
        return models_df

    def get_embeddings(self, texts):
        """Pass in a list of strings. Returns a list of embeddings for each."""
        result = Embedding.create(input=texts, model=MODEL_ID)
        #print(len(result["data"]))
        return [d["embedding"] for d in result["data"]]
    

ai = OpenAIService()

#models_df = ai.get_models()
#models_df.head()

texts = [
    "I like apples, but bananas are gross.",
    "This is a tweet about bananas",
    "Drink apple juice!",
]
embeddings = ai.get_embeddings(texts)
print(len(embeddings))
print(len(embeddings[0]))

from pandas import Series

Series(embeddings, index=texts)

"""## Users Sample

Fetch a sample of users. Use the balanced sample we already prepared.
"""

from pandas import read_csv

def remove_delimeters(txt):
    return txt.replace(" || ", " ")

users_df = read_csv(users_sample_csv_filepath)
users_df.drop(columns=["Unnamed: 0"], inplace=True, errors="ignore")
users_df.index = users_df["user_id"]
# remove delimeters inserted during the data export process:
users_df["tweet_texts"] = users_df["tweet_texts"].apply(remove_delimeters).tolist()

print(len(users_df))
print(users_df.columns)
users_df.iloc[0]

#users_df["profile_descriptions"].tolist()[0:5]

#users_df["tweet_texts"].tolist()[0:5]

"""## Embeddings

> NOTE: it seems we get an error when trying to process certain texts. Oh there are Nans? We will need to remove the nans before processing. And join them back together at the end.
"""

#users_df["profile_descriptions"].isna()
#users_df["profile_descriptions"].notnull()

"""> ALSO: Series is not JSON serializable, so we will request the embeddings for a list of strings instead of a series.

### Profile Embeddings
"""

profiles_df = users_df[users_df["profile_descriptions"].notnull()][["user_id", "profile_descriptions"]]
#profiles.head()

profile_texts = profiles_df["profile_descriptions"].tolist()
print("PROFILE TEXTS:", len(profile_texts))
print(profile_texts[0:5])

profile_embeddings = ai.get_embeddings(profile_texts) # API CALL
print("PROFILE EMBEDDINGS:", len(profile_embeddings))
print(len(profile_embeddings[0]))
print(profile_embeddings[0])

profiles_df["embeddings"] = profile_embeddings

#profiles_df["embeddings"].iloc[0]

"""### Tweet Embeddings"""

tweets_df =  users_df[users_df["tweet_texts"].notnull()][["user_id", "tweet_texts"]]

tweet_texts = tweets_df["tweet_texts"].tolist()
print("TWEET TEXTS:", len(tweet_texts))
print(tweet_texts[0:5])

tweet_embeddings = ai.get_embeddings(tweet_texts) # API CALL
print("TWEET EMBEDDINGS:", len(tweet_embeddings))

tweets_df["embeddings"] = tweet_embeddings

"""## Save Embeddings"""

embeds_df = users_df.merge(profiles_df["embeddings"], left_index=True, right_index=True)
embeds_df.rename(columns={"embeddings": "profile_embeddings"}, inplace=True)

embeds_df = embeds_df.merge(tweets_df["embeddings"], left_index=True, right_index=True)
embeds_df.rename(columns={"embeddings": "tweet_embeddings"}, inplace=True)

#embeds_df.head()

model_dirpath = os.path.join(DATA_DIR, MODEL_ID)
os.makedirs(model_dirpath, exist_ok=True)

embeddings_csv_filepath = os.path.join(model_dirpath, "users_sample_openai_embeddings.csv")
print(embeddings_csv_filepath)

embeds_df.to_csv(embeddings_csv_filepath)