# -*- coding: utf-8 -*-
"""OpenAI Tweet Embeddings - Merging Remaining BOM Scores

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/123PguCmtPwTQqnynju0mD4f7iWNwnMlt

Looks like we originally didn't include the "bom_overall" score in the data file, so let's load the file from drive, query the database to obtain the scores, and merge the scores in.

## Query to Obtain Scores
"""

from google.colab import auth

# asks you to login
auth.authenticate_user()

from google.cloud import bigquery
from pandas import DataFrame

class BigQueryService():
    def __init__(self):
        self.client = bigquery.Client(project="tweet-research-shared")

    def execute_query(self, sql, verbose=True):
        if verbose == True:
            print(sql)
        job = self.client.query(sql)
        return job.result()

    def query_to_df(self, sql, verbose=True):
        """high-level wrapper to return a DataFrame"""
        results = self.execute_query(sql, verbose=verbose)
        records = [dict(row) for row in list(results)]
        df = DataFrame(records)
        return df

bq = BigQueryService()
print(bq)

print("------------")
print("QUERY:")
sql = """
    SELECT *
    FROM `tweet-research-shared.impeachment_2020.tweets_v2`
    LIMIT 10
"""

results = list(bq.execute_query(sql, verbose=True))
records = [dict(row) for row in results]
print("------------")
print("RESULTS:" , len(records))

sql = f"""
    SELECT
        u.user_id
        ,u.is_bot
        ,u.is_q ,u.opinion_community
        ,u.avg_fact_score, u.avg_toxicity, u.created_on

        --bom.user_id
        ,bom.score_type as bom_score_type
        ,count(distinct bom.lookup_at) as bom_lookup_count
        ,avg(bom.cap) as bom_cap
        ,avg(bom.astroturf) as bom_astroturf
        ,avg(bom.fake_follower) as bom_fake_follower
        ,avg(bom.financial) as bom_financial
        ,avg(bom.other) as bom_other
        ,avg(bom.overall) as bom_overall
        ,avg(bom.self_declared) as bom_self_declared
        ,avg(bom.spammer) as bom_spammer
    FROM `tweet-research-shared.impeachment_2020.botometer_scores` bom
    JOIN `tweet-research-shared.impeachment_2020.user_details_v20210806_slim` u ON bom.user_id = u.user_id -- 8683
    WHERE bom.score_type = 'english' -- 7,566 users with english scores
    GROUP BY 1,2,3,4,5,6,7,8
    -- HAVING lookup_count > 1 -- 333 users have multiple lookups, so we're going to average them instead of drop them
"""
bom_score_results = bq.query_to_df(sql, verbose=False)
bom_score_results.index = bom_score_results["user_id"]
bom_score_results.head()

scores_lookup = bom_score_results[["bom_overall", "bom_self_declared", "bom_spammer"]]
scores_lookup.head()

"""### Load Data from Google Drive"""

import os
from google.colab import drive

drive.mount('/content/drive')
print(os.getcwd(), os.listdir(os.getcwd())) #> 'content', ['.config', 'drive', 'sample_data']

# you might need to create a google drive SHORTCUT that has this same path
# ... or update the path to use your own google drive organization
DATA_DIR = '/content/drive/MyDrive/Research/DS Research Shared 2023/data/impeachment_2020'
print(DATA_DIR)
assert os.path.isdir(DATA_DIR)

MODEL_ID = "text-embedding-ada-002"

#embeddings_csv_filepath = os.path.join(DATA_DIR, MODEL_ID, "botometer_sample_openai_embeddings_20230704.csv") # messy format
#assert os.path.isfile(embeddings_csv_filepath)

tweet_embeddings_csv_filepath = os.path.join(DATA_DIR, MODEL_ID, "botometer_sample_openai_tweet_embeddings_20230704.csv.gz") # column per embedding, with label cols
assert os.path.isfile(tweet_embeddings_csv_filepath)

from pandas import read_csv

df = read_csv(tweet_embeddings_csv_filepath)
#df.drop(columns=["Unnamed: 0"], inplace=True)
df.index = df["user_id"]
print(df.columns.tolist())
df.head()

[col for col in df.columns if "bom_" in col]

"""## Merge In Scores"""

merged_df = df.merge(scores_lookup, how="left", left_index=True, right_index=True)
merged_df[["user_id", "is_bot", "bom_overall", "bom_astroturf"]].head()

merged_df["bom_overall"].isna().sum()

[col for col in merged_df.columns if "bom_" in col]

"""Save new version to drive (then download for local analysis as well):"""

new_csv_filepath = os.path.join(DATA_DIR, "text-embedding-ada-002", "botometer_sample_openai_tweet_embeddings_20230724.csv.gz")

merged_df.to_csv(new_csv_filepath, compression="gzip", index=False)





